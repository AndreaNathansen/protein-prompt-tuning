{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/kevin.klein/miniconda3/envs/prot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.4302726149559021"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from esm_likelihood import get_esm_likelihood_scores\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "testset_file = '../datasets/InterProUniprotPF03272prepared_test.fasta'\n",
    "testset = list(SeqIO.parse(testset_file, 'fasta'))\n",
    "\n",
    "# filter sequences with more than 1024 amino acids because ESM can't handle longer sequences\n",
    "testset = [seq for seq in testset if len(seq) <= 1024]\n",
    "\n",
    "# Calculate cutoff (10th percentile of ESM likelihood scores for the test set)\n",
    "#testset_df = get_esm_likelihood_scores(testset)\n",
    "testset_df = pd.read_csv(\"intermediate/basemodel-RITA_l-generated.fasta_testset_scores.csv\")\n",
    "cutoff = testset_df['score'].quantile(q=0.1)\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "results = {}\n",
    "\n",
    "for file in glob.glob(\"intermediate/*fasta_scores.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    filtered = df[df['score'] > cutoff]\n",
    "    ids = list(filtered['id'])\n",
    "    results[file] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate/finetuned-RITA_xl-generated.fasta_scores.csv 81\n",
      "intermediate/finetuned-RITA_m-generated.fasta_scores.csv 33\n",
      "intermediate/prompt-tuning-clustered-100-RITA_l-fromvocab-True-seed-0-generated.fasta_scores.csv 8\n",
      "intermediate/prompt-tuning-clustered-100-RITA_m-fromvocab-True-seed-0-generated.fasta_scores.csv 5\n",
      "intermediate/prompt-tuning-clustered-100-RITA_xl-fromvocab-True-seed-1-generated.fasta_scores.csv 18\n",
      "intermediate/prompt-tuning-clustered-100-RITA_s-fromvocab-True-seed-0-generated.fasta_scores.csv 4\n",
      "intermediate/prompt-tuning-clustered-100-RITA_l-fromvocab-True-seed-2-generated.fasta_scores.csv 10\n",
      "intermediate/prompt-tuning-clustered-100-RITA_s-fromvocab-True-seed-1-generated.fasta_scores.csv 5\n",
      "intermediate/prompt-tuning-clustered-100-RITA_s-fromvocab-True-seed-2-generated.fasta_scores.csv 6\n",
      "intermediate/basemodel-RITA_l-generated.fasta_scores.csv 15\n",
      "intermediate/finetuned-RITA_l-generated.fasta_scores.csv 60\n",
      "intermediate/basemodel-RITA_xl-generated.fasta_scores.csv 10\n",
      "intermediate/prompt-tuning-clustered-100-RITA_xl-fromvocab-True-seed-0-generated.fasta_scores.csv 18\n",
      "intermediate/prompt-tuning-clustered-100-RITA_l-fromvocab-True-seed-1-generated.fasta_scores.csv 8\n",
      "intermediate/finetuned-RITA_s-generated.fasta_scores.csv 20\n",
      "intermediate/prompt-tuning-clustered-100-RITA_m-fromvocab-True-seed-2-generated.fasta_scores.csv 7\n",
      "intermediate/prompt-tuning-clustered-100-RITA_m-fromvocab-True-seed-1-generated.fasta_scores.csv 6\n",
      "intermediate/prompt-tuning-clustered-100-RITA_xl-fromvocab-True-seed-2-generated.fasta_scores.csv 19\n",
      "intermediate/basemodel-RITA_m-generated.fasta_scores.csv 11\n",
      "intermediate/basemodel-RITA_s-generated.fasta_scores.csv 5\n"
     ]
    }
   ],
   "source": [
    "for k,v in results.items():\n",
    "    print(k,len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "num_seqences_per_file = 193\n",
    "\n",
    "pattern = re.compile(\".*(RITA_\\w{1,2})-.*\")\n",
    "getModel = lambda filename: pattern.match(filename).groups()[0]\n",
    "\n",
    "data = [\n",
    "    (getModel(k), 'pt', len(v)*100/num_seqences_per_file) if 'prompt-tuning' in k \n",
    "    else ((getModel(k),'base',len(v)*100/num_seqences_per_file)) if 'basemodel' in k\n",
    "    else ((getModel(k),'fine',len(v)*100/num_seqences_per_file))\n",
    "    for k,v in results.items()\n",
    "]\n",
    "\n",
    "order = ['RITA_s', 'RITA_m', 'RITA_l', 'RITA_xl']\n",
    "data = sorted(data, key=lambda item: order.index(item[0]))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "keys, _, values = list(zip(*[t for t in data if t[1] == 'pt']))\n",
    "plt.scatter(keys, values, c = 'b', label='prompt-tuned')\n",
    "\n",
    "keys, _, values = list(zip(*[t for t in data if t[1] == 'base']))\n",
    "plt.scatter(keys, values, c = 'g', label='base')\n",
    "\n",
    "keys, _, values = list(zip(*[t for t in data if t[1] == 'fine']))\n",
    "plt.scatter(keys, values, c = 'y', label='finetuned')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
