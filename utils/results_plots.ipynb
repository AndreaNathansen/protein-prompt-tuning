{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "TESTSET_SIZE = 193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hpi/fs00/home/andrea.nathansen/protein-prompt-tuning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_hmmer_recognized_sequences(hmmer_result_filepath):\n",
    "    # The resulting tabular files are in a format that they can't be read\n",
    "    # as a normal dataframe. So we count the lines that do not start with #\n",
    "    # and are not empty, because those are the entries of recognized sequences\n",
    "    with open(hmmer_result_filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        recognized_sequences = 0\n",
    "        for line in lines:\n",
    "            if not (line.startswith('#') or line == ''):\n",
    "                recognized_sequences += 1\n",
    "    return recognized_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentage_hmmer_recognized_sequences_testset_size(hmmer_result_filepath):\n",
    "    # assuming a dataset with the same size as the testset\n",
    "    return get_number_hmmer_recognized_sequences(hmmer_result_filepath) / TESTSET_SIZE * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentage_hmmer_recognized_sequences_prompttuning(hmmer_result_filepaths):\n",
    "    percentages_recognized = np.array([get_percentage_hmmer_recognized_sequences_testset_size(filepath) for filepath in hmmer_result_filepaths])\n",
    "    return percentages_recognized.mean(), percentages_recognized.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexities_ablation(result_df):\n",
    "    # Aggregate over runs with different random seeds for prompt-tuned models.\n",
    "    # Ablation is done on validation set.\n",
    "    return result_df[\"val\"].mean(), result_df[\"val\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexities_trainvaltest(result_df):\n",
    "    # Aggregate over runs with different random seeds for prompt-tuned models.\n",
    "    # Results for training, validation and test set\n",
    "    return result_df[\"train\"].mean(), result_df[\"train\"].std(), result_df[\"val\"].mean(), result_df[\"val\"].std(), result_df[\"test\"].mean(), result_df[\"test\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexities_comparison_to_basemodel(result_df):\n",
    "    # Aggregate over runs with different random seeds for prompt-tuned models.\n",
    "    # Base model model wasn't affected by different random seeds.\n",
    "    return result_df[\"prompt_tuned\"].mean(), result_df[\"prompt_tuned\"].std(), result_df[\"base\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testset_perplexities_from_trainvaltest_finetuned(result_df):\n",
    "    # Finetuned model has only one run per configuration\n",
    "    return result_df[\"test\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_protcnn_family_percentage_single_df(result_df):\n",
    "    # The percentage of proteins that were classified as the family\n",
    "    return (result_df[\"is_family\"].sum() / len(result_df[\"is_family\"])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_protcnn_precision_recall_metrics(positives_df, negative_dfs):\n",
    "    # Precision and recall for classification of the family, for a dataset\n",
    "    # that actually belongs to that family and negative control datasets\n",
    "    negative_df_concatenated = pd.concat([df for df in negative_dfs])\n",
    "    true_positives = positives_df[\"is_family\"].sum()\n",
    "    false_negatives = len(positives_df) - true_positives\n",
    "    false_positives = negative_df_concatenated[\"is_family\"].sum()\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_protcnn_family_percentage_aggregated(result_dfs):\n",
    "    percentages = [get_results_protcnn_family_percentage_single_df(df) for df in result_dfs]\n",
    "    return np.mean(percentages), np.std(percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_protcnn_family_percentage_concatenated(result_dfs):\n",
    "    percentage = get_results_protcnn_family_percentage_single_df(pd.concat([df for df in result_dfs]))\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_ram_usage(result_df):\n",
    "    return result_df[\"total_peak\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results_table_protcnn_datasets(column_names, row_names, result_dfs_protcnn_configurations):\n",
    "    table=pd.DataFrame(columns=column_names, index=row_names)\n",
    "\n",
    "    for j, result_dfs_protcnn_datasets in enumerate(result_dfs_protcnn_configurations):\n",
    "        for i, result_dfs_protcnn_dataset in enumerate(result_dfs_protcnn_datasets):\n",
    "            # results for datasets might be split into multiple dataframes for sets with large sequences\n",
    "            if isinstance(result_dfs_protcnn_dataset, list):\n",
    "                r_dataset = get_results_protcnn_family_percentage_concatenated(result_dfs_protcnn_dataset)\n",
    "            else:\n",
    "                r_dataset = get_results_protcnn_family_percentage_single_df(result_dfs_protcnn_dataset)\n",
    "            table[column_names[i]].loc[row_names[j]] = f\"{np.round(r_dataset, decimals=1)}\"\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_precision_recall_table_protcnn_datasets(row_names, result_dfs_positive_protcnn_configurations, result_dfs_negative_protcnn_configurations):\n",
    "    table=pd.DataFrame(columns=[\"Precision\", \"Recall\"], index=row_names)\n",
    "    \n",
    "    for i, result_dfs_protcnn_datasets in enumerate(zip(result_dfs_positive_protcnn_configurations, result_dfs_negative_protcnn_configurations)):\n",
    "        result_df_positive_datasets, result_dfs_negative_datasets = result_dfs_protcnn_datasets\n",
    "        precision, recall = get_results_protcnn_precision_recall_metrics(result_df_positive_datasets, result_dfs_negative_datasets)\n",
    "        table.loc[row_names[i]] = {\"Precision\": f\"{np.round(precision, decimals=2)}\", \"Recall\": f\"{np.round(recall, decimals=2)}\"}\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results_table_protcnn_comparison(column_names, result_dfs_protcnn_prompttuned, result_dfs_protcnn_finetuned, result_dfs_protcnn_basemodel):\n",
    "    table=pd.DataFrame(columns=column_names, index=[\"Prompt-tuned model (ours)\", \"Finetuned model\", \"Base model\"])\n",
    "    for i, dfs in enumerate(zip(result_dfs_protcnn_prompttuned, result_dfs_protcnn_finetuned, result_dfs_protcnn_basemodel)):\n",
    "        result_dfs_protcnn_prompttuned_seeds, result_df_protcnn_finetuned, result_df_protcnn_basemodel = dfs\n",
    "        r_prompttuned_mean, r_prompttuned_std = get_results_protcnn_family_percentage_aggregated(result_dfs_protcnn_prompttuned_seeds)\n",
    "        r_finetuned = get_results_protcnn_family_percentage_single_df(result_df_protcnn_finetuned)\n",
    "        r_basemodel = get_results_protcnn_family_percentage_single_df(result_df_protcnn_basemodel)\n",
    "        table[column_names[i]] = [f\"{np.round(r_prompttuned_mean, decimals=2)} ± {np.round(r_prompttuned_std, decimals=2)}\",\n",
    "                                  np.round(r_finetuned, decimals=2),\n",
    "                                  np.round(r_basemodel, decimals=2)]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results_table_protcnn_for_clustering_comparison(column_names, result_dfs_protcnn_prompttuned):\n",
    "    table=pd.DataFrame(columns=column_names, index=[\"Prompt-tuned model (ours)\"])\n",
    "    for i, dfs in enumerate(result_dfs_protcnn_prompttuned):\n",
    "        r_prompttuned_mean, r_prompttuned_std = get_results_protcnn_family_percentage_aggregated(dfs)\n",
    "        table[column_names[i]] = [f\"{np.round(r_prompttuned_mean, decimals=2)} ± {np.round(r_prompttuned_std, decimals=2)}\"]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perplexities_table_for_clustering_comparison(column_names, result_dfs_clusterings):\n",
    "    table=pd.DataFrame(columns=column_names, index=[\"Train\", \"Validation\", \"Test\"])\n",
    "    for i, df in enumerate(result_dfs_clusterings):\n",
    "            r_train_mean, r_train_std, r_val_mean, r_val_std, r_test_mean, r_test_std, = get_perplexities_trainvaltest(df)\n",
    "            table[column_names[i]] = [f\"{np.round(r_train_mean, decimals=2)} ± {np.round(r_train_std, decimals=2)}\", f\"{np.round(r_val_mean, decimals=2)} ± {np.round(r_val_std, decimals=2)}\", f\"{np.round(r_test_mean, decimals=2)} ± {np.round(r_test_std, decimals=2)}\"]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perplexities_table_for_ablation_study(column_names, row_names, result_dfs_ablations):\n",
    "    table=pd.DataFrame(columns=column_names, index=row_names)\n",
    "    for j, result_dfs_for_ablation in enumerate(result_dfs_ablations):\n",
    "        for i, df in enumerate(result_dfs_for_ablation):\n",
    "            r_mean, r_std = get_perplexities_ablation(df)\n",
    "            table[column_names[i]][row_names[j]] = f\"{np.round(r_mean, decimals=2)} ± {np.round(r_std, decimals=2)}\"\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perplexities_table_for_comparison_to_basemodel(column_names, result_dfs):\n",
    "    table=pd.DataFrame(columns=column_names, index=[\"Prompt-tuned model (ours)\", \"Base model\"])\n",
    "    for i, df in enumerate(result_dfs):\n",
    "        r_prompttuned_mean, r_prompttuned_std, r_basemodel = get_perplexities_comparison_to_basemodel(df)\n",
    "        table[column_names[i]] = [f\"{np.round(r_prompttuned_mean, decimals=2)} ± {np.round(r_prompttuned_std, decimals=2)}\", np.round(r_basemodel, decimals=2)]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perplexities_table_comparison_prompttuned_finetuned_basemodel(column_names, result_dfs_prompttuned_basemodel, result_dfs_finetuned):\n",
    "    table=pd.DataFrame(columns=column_names, index=[\"Prompt-tuned model (ours)\", \"Finetuned model\", \"Base model\"])\n",
    "    for i, dfs in enumerate(zip(result_dfs_prompttuned_basemodel, result_dfs_finetuned)):\n",
    "        result_df_prompttuned_basemodel, result_df_finetuned = dfs\n",
    "        r_prompttuned_mean, r_prompttuned_std, r_basemodel = get_perplexities_comparison_to_basemodel(result_df_prompttuned_basemodel)\n",
    "        r_finetuned = get_testset_perplexities_from_trainvaltest_finetuned(result_df_finetuned)\n",
    "        table[column_names[i]] = [f\"{np.round(r_prompttuned_mean, decimals=2)} ± {np.round(r_prompttuned_std, decimals=2)}\",\n",
    "                                  np.round(r_finetuned, decimals=2),\n",
    "                                  np.round(r_basemodel, decimals=2)]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hmmer_results_table_comparison_prompttuned_finetuned_basemodel(column_names,\n",
    "                                                                            hmmer_result_paths_prompttuned,\n",
    "                                                                            hmmer_result_paths_basemodel,\n",
    "                                                                            hmmer_result_paths_finetuned):\n",
    "    table=pd.DataFrame(columns=column_names, index=[\"Prompt-tuned model (ours)\", \"Finetuned model\", \"Base model\"])\n",
    "    for i, hmmer_result_paths in enumerate(zip(hmmer_result_paths_prompttuned, hmmer_result_paths_basemodel, hmmer_result_paths_finetuned)):\n",
    "        rp_prompttuned, rp_basemodel, rp_finetuned = hmmer_result_paths\n",
    "        r_prompttuned_mean, r_prompttuned_std = get_percentage_hmmer_recognized_sequences_prompttuning(rp_prompttuned)\n",
    "        r_basemodel = get_percentage_hmmer_recognized_sequences_testset_size(rp_basemodel)\n",
    "        r_finetuned = get_percentage_hmmer_recognized_sequences_testset_size(rp_finetuned)\n",
    "        table[column_names[i]] = [f\"{np.round(r_prompttuned_mean, decimals=2)} ± {np.round(r_prompttuned_std, decimals=2)}\",\n",
    "                                  np.round(r_finetuned, decimals=2),\n",
    "                                  np.round(r_basemodel, decimals=2)]\n",
    "    return table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ram_usages_table_comparison_prompttuned_finetuned(column_names,\n",
    "                                                                            result_dfs_prompttuned,\n",
    "                                                                            result_dfs_finetuned):\n",
    "    table=pd.DataFrame(columns=column_names, index=[\"Prompt-tuned model (ours)\", \"Finetuned model\"])\n",
    "    for i, dfs in enumerate(zip(result_dfs_prompttuned, result_dfs_finetuned)):\n",
    "        result_df_prompttuned, result_df_finetuned = dfs\n",
    "        r_prompttuned = get_peak_ram_usage(result_df_prompttuned)\n",
    "        r_finetuned = get_peak_ram_usage(result_df_finetuned)\n",
    "        table[column_names[i]] = [r_prompttuned,\n",
    "                                  r_finetuned]\n",
    "    return table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of prompt tuning (with defaults) for all model sizes, comparison to base model and finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_defaults_S = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100-RITA_s-fromvocab-True-test_perplexity_comparison.csv\")\n",
    "test_results_defaults_M = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100-RITA_m-fromvocab-True-test_perplexity_comparison.csv\")\n",
    "test_results_defaults_L = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100-RITA_l-fromvocab-True-test_perplexity_comparison.csv\")\n",
    "test_results_defaults_XL = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100-RITA_xl-fromvocab-True-test_perplexity_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_finetuned_S = pd.read_csv(\"experiment_results/perplexities/finetuned-RITA_s-trainvaltest_comparison.csv\")\n",
    "test_results_finetuned_M = pd.read_csv(\"experiment_results/perplexities/finetuned-RITA_m-trainvaltest_comparison.csv\")\n",
    "test_results_finetuned_L = pd.read_csv(\"experiment_results/perplexities/finetuned-RITA_l-trainvaltest_comparison.csv\")\n",
    "test_results_finetuned_XL = pd.read_csv(\"experiment_results/perplexities/finetuned-RITA_xl-trainvaltest_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>M</th>\n",
       "      <th>L</th>\n",
       "      <th>XL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prompt-tuned model (ours)</th>\n",
       "      <td>8.73 ± 0.1</td>\n",
       "      <td>7.25 ± 0.19</td>\n",
       "      <td>6.01 ± 0.5</td>\n",
       "      <td>5.96 ± 0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finetuned model</th>\n",
       "      <td>1.49</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base model</th>\n",
       "      <td>13.93</td>\n",
       "      <td>12.31</td>\n",
       "      <td>9.65</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    S            M           L           XL\n",
       "Prompt-tuned model (ours)  8.73 ± 0.1  7.25 ± 0.19  6.01 ± 0.5  5.96 ± 0.72\n",
       "Finetuned model                  1.49         1.39        1.37         1.38\n",
       "Base model                      13.93        12.31        9.65         6.98"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_defaults_all_sizes = generate_perplexities_table_comparison_prompttuned_finetuned_basemodel([\"S\", \"M\", \"L\", \"XL\"], [test_results_defaults_S, test_results_defaults_M, test_results_defaults_L, test_results_defaults_XL],\n",
    "                                                                              [test_results_finetuned_S, test_results_finetuned_M, test_results_finetuned_L, test_results_finetuned_XL])\n",
    "table_defaults_all_sizes.to_csv(\"experiment_results/final_tables/results_perplexity_model_sizes.csv\")\n",
    "table_defaults_all_sizes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for ablation study random uniform init VS from vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvaltest_results_fromvocab_S = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100-RITA_s-fromvocab-True-trainvaltest_comparison.csv\")\n",
    "trainvaltest_results_fromvocab_M = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100-RITA_m-fromvocab-True-trainvaltest_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvaltest_results_randomuniform_S = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100_s_random_init-RITA_s-fromvocab-False-trainvaltest_comparison.csv\")\n",
    "trainvaltest_results_randomuniform_M = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100_m_random_init-RITA_m-fromvocab-False-trainvaltest_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sampled Vocab</th>\n",
       "      <td>8.21 ± 0.08</td>\n",
       "      <td>6.8 ± 0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Uniform</th>\n",
       "      <td>8.18 ± 0.19</td>\n",
       "      <td>7.05 ± 0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          S            M\n",
       "Sampled Vocab   8.21 ± 0.08   6.8 ± 0.17\n",
       "Random Uniform  8.18 ± 0.19  7.05 ± 0.33"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_ablation_study = generate_perplexities_table_for_ablation_study([\"S\", \"M\"], [\"Sampled Vocab\", \"Random Uniform\"],[[trainvaltest_results_fromvocab_S, trainvaltest_results_fromvocab_M], [trainvaltest_results_randomuniform_S, trainvaltest_results_randomuniform_M]])\n",
    "table_ablation_study.to_csv(\"experiment_results/final_tables/results_perplexity_ablation_study.csv\")\n",
    "table_ablation_study"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for different clustering sequence similarity thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvaltest_results_clustering_100 = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100-RITA_s-fromvocab-True-trainvaltest_comparison.csv\")\n",
    "trainvaltest_results_clustering_95 = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-95-RITA_s-fromvocab-True-trainvaltest_comparison.csv\")\n",
    "trainvaltest_results_clustering_65 = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-65-RITA_s-fromvocab-True-trainvaltest_comparison.csv\")\n",
    "trainvaltest_results_clustering_35 = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-35-RITA_s-fromvocab-True-trainvaltest_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>95</th>\n",
       "      <th>65</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>8.25 ± 0.08</td>\n",
       "      <td>10.13 ± 0.03</td>\n",
       "      <td>11.72 ± 0.1</td>\n",
       "      <td>11.66 ± 0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>8.21 ± 0.08</td>\n",
       "      <td>9.65 ± 0.02</td>\n",
       "      <td>13.08 ± 0.1</td>\n",
       "      <td>12.15 ± 0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>8.73 ± 0.1</td>\n",
       "      <td>9.64 ± 0.02</td>\n",
       "      <td>12.67 ± 0.08</td>\n",
       "      <td>13.49 ± 0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    100           95            65            35 \n",
       "Train       8.25 ± 0.08  10.13 ± 0.03   11.72 ± 0.1  11.66 ± 0.12\n",
       "Validation  8.21 ± 0.08   9.65 ± 0.02   13.08 ± 0.1  12.15 ± 0.06\n",
       "Test         8.73 ± 0.1   9.64 ± 0.02  12.67 ± 0.08  13.49 ± 0.07"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_trainvaltest_clustering = generate_perplexities_table_for_clustering_comparison([100, 95, 65, 35], [trainvaltest_results_clustering_100,trainvaltest_results_clustering_95, trainvaltest_results_clustering_65, trainvaltest_results_clustering_35])\n",
    "table_trainvaltest_clustering.to_csv(\"experiment_results/final_tables/results_perplexity_clustering_trainvaltest.csv\")\n",
    "table_trainvaltest_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel_results_clustering_100 = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-100-RITA_s-fromvocab-True-test_perplexity_comparison.csv\")\n",
    "basemodel_results_clustering_95 = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-95-RITA_s-fromvocab-True-test_perplexity_comparison.csv\")\n",
    "basemodel_results_clustering_65 = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-65-RITA_s-fromvocab-True-test_perplexity_comparison.csv\")\n",
    "basemodel_results_clustering_35 = pd.read_csv(\"experiment_results/perplexities/prompt-tuning-clustered-35-RITA_s-fromvocab-True-test_perplexity_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>95</th>\n",
       "      <th>65</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prompt-tuned model (ours)</th>\n",
       "      <td>8.73 ± 0.1</td>\n",
       "      <td>9.64 ± 0.02</td>\n",
       "      <td>12.67 ± 0.08</td>\n",
       "      <td>13.49 ± 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base model</th>\n",
       "      <td>13.93</td>\n",
       "      <td>12.99</td>\n",
       "      <td>13.83</td>\n",
       "      <td>14.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  100          95            65            35 \n",
       "Prompt-tuned model (ours)  8.73 ± 0.1  9.64 ± 0.02  12.67 ± 0.08  13.49 ± 0.07\n",
       "Base model                      13.93        12.99         13.83         14.24"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_basemodelcomparison_clustering = generate_perplexities_table_for_comparison_to_basemodel([100, 95, 65, 35], [basemodel_results_clustering_100, basemodel_results_clustering_95, basemodel_results_clustering_65, basemodel_results_clustering_35])\n",
    "table_basemodelcomparison_clustering.to_csv(\"experiment_results/final_tables/results_perplexity_clustering_basemodelcomparison.csv\")\n",
    "table_basemodelcomparison_clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for protCNN predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for test dataset and negative control datasets\n",
    "For different ProtCNN configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "protcnn_results_testset_single = pd.read_csv(\"experiment_results/protcnn-eval_single/InterProUniprotPF03272prepared_test.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.0.csv\")\n",
    "protcnn_results_otherfamilies_single = pd.read_csv(\"experiment_results/protcnn-eval_single/other-families.fasta_protcnn_results_flexible_windowsize_stride1.csv\")\n",
    "protcnn_results_shuffled_single = pd.read_csv(\"experiment_results/protcnn-eval_single/esl-shuffled.fasta_protcnn_results_flexible_windowsize_stride1.csv\")\n",
    "\n",
    "\n",
    "protcnn_results_testset_ensemble2 = pd.read_csv(\"experiment_results/protcnn-eval-ensemble-2/InterProUniprotPF03272prepared_test.fasta_protcnn_results_flexible_windowsize_stride1_ensemble2.csv\")\n",
    "protcnn_results_otherfamilies_ensemble2 = [pd.read_csv(result_csv) for result_csv in glob.glob(\"experiment_results/protcnn-eval-ensemble-2/other-families*\")]\n",
    "protcnn_results_shuffled_ensemble2 = pd.read_csv(\"experiment_results/protcnn-eval-ensemble-2/esl-shuffled.fasta_protcnn_results_flexible_windowsize_stride1_ensemble2.csv\")\n",
    "\n",
    "protcnn_results_testset_ensemble3 = pd.read_csv(\"experiment_results/protcnn-eval-ensemble-3/InterProUniprotPF03272prepared_test.fasta_protcnn_results_flexible_windowsize_stride1.csv\")\n",
    "protcnn_results_otherfamilies_ensemble3 = [pd.read_csv(result_csv) for result_csv in glob.glob(\"experiment_results/protcnn-eval-ensemble-3/other-families*\")]\n",
    "protcnn_results_shuffled_ensemble3 = pd.read_csv(\"experiment_results/protcnn-eval-ensemble-3/esl-shuffled.fasta_protcnn_results_flexible_windowsize_stride1.csv\")\n",
    "\n",
    "protcnn_results_testset_threshold = pd.read_csv(\"experiment_results/protcnn-eval-threshold0.5/InterProUniprotPF03272prepared_test.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")\n",
    "protcnn_results_otherfamilies_threshold = [pd.read_csv(result_csv) for result_csv in glob.glob(\"experiment_results/protcnn-eval-threshold0.5/other-families*\")]\n",
    "protcnn_results_shuffled_threshold = pd.read_csv(\"experiment_results/protcnn-eval-threshold0.5/esl-shuffled.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test set</th>\n",
       "      <th>Other families</th>\n",
       "      <th>Shuffled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Single</th>\n",
       "      <td>99.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>89.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 2</th>\n",
       "      <td>98.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>83.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 3</th>\n",
       "      <td>98.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>82.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single thresholded</th>\n",
       "      <td>99.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>65.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Test set Other families Shuffled\n",
       "Single                 99.0           24.2     89.1\n",
       "Ensemble 2             98.4           18.9     83.4\n",
       "Ensemble 3             98.4           21.6     82.9\n",
       "Single thresholded     99.0           13.2     65.3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_protcnn_datasets = generate_results_table_protcnn_datasets(column_names=[\"Test set\", \"Other families\", \"Shuffled\"],\n",
    "                                        row_names=[\"Single\", \"Ensemble 2\", \"Ensemble 3\", \"Single thresholded\"], \n",
    "                                        result_dfs_protcnn_configurations=[[protcnn_results_testset_single, protcnn_results_otherfamilies_single, protcnn_results_shuffled_single],\n",
    "                                                                           [protcnn_results_testset_ensemble2, protcnn_results_otherfamilies_ensemble2, protcnn_results_shuffled_ensemble2],\n",
    "                                                                           [protcnn_results_testset_ensemble3, protcnn_results_otherfamilies_ensemble3, protcnn_results_shuffled_ensemble3],\n",
    "                                                                           [protcnn_results_testset_threshold, protcnn_results_otherfamilies_threshold, protcnn_results_shuffled_threshold]])\n",
    "results_protcnn_datasets.to_csv(\"experiment_results/final_tables/results_protcnn_datasets.csv\")\n",
    "results_protcnn_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Single</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 2</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble 3</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single thresholded</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Precision Recall\n",
       "Single                  0.47   0.99\n",
       "Ensemble 2              0.49   0.98\n",
       "Ensemble 3              0.49   0.98\n",
       "Single thresholded      0.56   0.99"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_precision_recall_protcnn_datasets = generate_precision_recall_table_protcnn_datasets(\n",
    "                                        row_names=[\"Single\", \"Ensemble 2\", \"Ensemble 3\", \"Single thresholded\"], \n",
    "                                        result_dfs_positive_protcnn_configurations=[protcnn_results_testset_single, protcnn_results_testset_ensemble2, protcnn_results_testset_ensemble3, protcnn_results_testset_threshold],\n",
    "                                        result_dfs_negative_protcnn_configurations=[[protcnn_results_otherfamilies_single, protcnn_results_shuffled_single],\n",
    "                                                                           protcnn_results_otherfamilies_ensemble2 + [protcnn_results_shuffled_ensemble2],\n",
    "                                                                           protcnn_results_otherfamilies_ensemble3 + [protcnn_results_shuffled_ensemble3],\n",
    "                                                                           protcnn_results_otherfamilies_threshold + [protcnn_results_shuffled_threshold]])\n",
    "results_precision_recall_protcnn_datasets.to_csv(\"experiment_results/final_tables/results_precision_recall_protcnn_datasets.csv\")\n",
    "results_precision_recall_protcnn_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for generated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "protcnn_results_clustering_100 = [pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/prompt-tuning-clustered-100-RITA_s-fromvocab-True-seed-{i}-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\") for i in range(3)]\n",
    "protcnn_results_clustering_95 = [pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/prompt-tuning-clustered-95-RITA_s-fromvocab-True-seed-{i}-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\") for i in range(3)]\n",
    "protcnn_results_clustering_65 = [pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/prompt-tuning-clustered-65-RITA_s-fromvocab-True-seed-{i}-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\") for i in range(3)]\n",
    "protcnn_results_clustering_35 = [pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/prompt-tuning-clustered-35-RITA_s-fromvocab-True-seed-{i}-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\") for i in range(3)]\n",
    "protcnn_results_basemodel = [pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/basemodel-RITA_s-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\") for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "protcnn_results_testdata = pd.read_csv(\"experiment_results/protcnn-eval-threshold0.5/InterProUniprotPF03272prepared_test.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>95</th>\n",
       "      <th>65</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prompt-tuned model (ours)</th>\n",
       "      <td>51.3 ± 4.08</td>\n",
       "      <td>52.85 ± 3.05</td>\n",
       "      <td>53.54 ± 8.94</td>\n",
       "      <td>52.16 ± 2.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   100           95            65   \\\n",
       "Prompt-tuned model (ours)  51.3 ± 4.08  52.85 ± 3.05  53.54 ± 8.94   \n",
       "\n",
       "                                    35   \n",
       "Prompt-tuned model (ours)  52.16 ± 2.09  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_protcnn_comparison_clustering = generate_results_table_protcnn_for_clustering_comparison([100, 95, 65, 35], [protcnn_results_clustering_100, protcnn_results_clustering_95, protcnn_results_clustering_65, protcnn_results_clustering_35])\n",
    "table_protcnn_comparison_clustering.to_csv(\"experiment_results/final_tables/results_protcnn_clustering.csv\")\n",
    "table_protcnn_comparison_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "protcnn_results_S = [pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/prompt-tuning-clustered-100-RITA_s-fromvocab-True-seed-{i}-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\") for i in range(3)]\n",
    "protcnn_results_M = [pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/prompt-tuning-clustered-100-RITA_m-fromvocab-True-seed-{i}-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\") for i in range(3)]\n",
    "protcnn_results_L = [pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/prompt-tuning-clustered-100-RITA_l-fromvocab-True-seed-{i}-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\") for i in range(3)]\n",
    "protcnn_results_XL = [pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/prompt-tuning-clustered-100-RITA_xl-fromvocab-True-seed-{i}-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\") for i in range(3)]\n",
    "\n",
    "protcnn_results_SBase = pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/basemodel-RITA_s-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")\n",
    "protcnn_results_MBase = pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/basemodel-RITA_m-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")\n",
    "protcnn_results_LBase = pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/basemodel-RITA_l-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")\n",
    "protcnn_results_XLBase = pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/basemodel-RITA_xl-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")\n",
    "\n",
    "protcnn_results_SFinetuned = pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/finetuned-RITA_s-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")\n",
    "protcnn_results_MFinetuned = pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/finetuned-RITA_m-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")\n",
    "protcnn_results_LFinetuned = pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/finetuned-RITA_l-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")\n",
    "protcnn_results_XLFinetuned = pd.read_csv(f\"experiment_results/protcnn-eval-threshold0.5/finetuned-RITA_xl-generated.fasta_protcnn_results_flexible_windowsize_stride1_threshold0.5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>M</th>\n",
       "      <th>L</th>\n",
       "      <th>XL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prompt-tuned model (ours)</th>\n",
       "      <td>51.3 ± 4.08</td>\n",
       "      <td>52.16 ± 5.51</td>\n",
       "      <td>39.72 ± 1.36</td>\n",
       "      <td>24.35 ± 1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finetuned model</th>\n",
       "      <td>67.36</td>\n",
       "      <td>75.13</td>\n",
       "      <td>80.31</td>\n",
       "      <td>70.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base model</th>\n",
       "      <td>9.84</td>\n",
       "      <td>11.92</td>\n",
       "      <td>13.47</td>\n",
       "      <td>16.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     S             M             L  \\\n",
       "Prompt-tuned model (ours)  51.3 ± 4.08  52.16 ± 5.51  39.72 ± 1.36   \n",
       "Finetuned model                  67.36         75.13         80.31   \n",
       "Base model                        9.84         11.92         13.47   \n",
       "\n",
       "                                     XL  \n",
       "Prompt-tuned model (ours)  24.35 ± 1.53  \n",
       "Finetuned model                   70.47  \n",
       "Base model                        16.58  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_protcnn_comparison_model_sizes = generate_results_table_protcnn_comparison([\"S\", \"M\", \"L\", \"XL\"],\n",
    "                                                                                 [protcnn_results_S, protcnn_results_M, protcnn_results_L, protcnn_results_XL],\n",
    "                                                                                 [protcnn_results_SFinetuned, protcnn_results_MFinetuned, protcnn_results_LFinetuned, protcnn_results_XLFinetuned],\n",
    "                                                                                 [protcnn_results_SBase, protcnn_results_MBase, protcnn_results_LBase, protcnn_results_XLBase])\n",
    "\n",
    "table_protcnn_comparison_model_sizes.to_csv(\"experiment_results/final_tables/results_protcnn_model_sizes.csv\")\n",
    "table_protcnn_comparison_model_sizes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for HMMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hmmer_result_path = \"experiment_results/hmmer_results/\"\n",
    "\n",
    "hmmer_result_paths_s = [base_hmmer_result_path + f\"hmmer_s_prompt-tuned_{i}.out\" for i in range(3)]\n",
    "hmmer_result_paths_m = [base_hmmer_result_path + f\"hmmer_m_prompt-tuned_{i}.out\" for i in range(3)]\n",
    "hmmer_result_paths_l = [base_hmmer_result_path + f\"hmmer_l_prompt-tuned_{i}.out\" for i in range(3)]\n",
    "hmmer_result_paths_xl = [base_hmmer_result_path + f\"hmmer_xl_prompt-tuned_{i}.out\" for i in range(3)]\n",
    "hmmer_results_paths_pt = [hmmer_result_paths_s, hmmer_result_paths_m, hmmer_result_paths_l, hmmer_result_paths_xl]\n",
    "\n",
    "hmmer_results_paths_bm = [base_hmmer_result_path + \"hmmer_s_basemodel.out\", base_hmmer_result_path + \"hmmer_m_basemodel.out\",\n",
    "                            base_hmmer_result_path + \"hmmer_l_basemodel.out\", base_hmmer_result_path + \"hmmer_xl_basemodel.out\"]\n",
    "\n",
    "hmmer_results_paths_ft = [base_hmmer_result_path + \"hmmer_s_finetuned.out\", base_hmmer_result_path + \"hmmer_m_finetuned.out\",\n",
    "                            base_hmmer_result_path + \"hmmer_l_finetuned.out\", base_hmmer_result_path + \"hmmer_xl_finetuned.out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>M</th>\n",
       "      <th>L</th>\n",
       "      <th>XL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prompt-tuned model (ours)</th>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "      <td>0.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finetuned model</th>\n",
       "      <td>24.87</td>\n",
       "      <td>33.16</td>\n",
       "      <td>48.7</td>\n",
       "      <td>54.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base model</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   S          M          L         XL\n",
       "Prompt-tuned model (ours)  0.0 ± 0.0  0.0 ± 0.0  0.0 ± 0.0  0.0 ± 0.0\n",
       "Finetuned model                24.87      33.16       48.7      54.92\n",
       "Base model                       0.0        0.0        0.0        0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_hmmer_results_all_sizes = generate_hmmer_results_table_comparison_prompttuned_finetuned_basemodel([\"S\", \"M\", \"L\", \"XL\"],\n",
    "                                                                                                        hmmer_results_paths_pt,\n",
    "                                                                                                        hmmer_results_paths_bm,\n",
    "                                                                                                        hmmer_results_paths_ft)\n",
    "table_hmmer_results_all_sizes.to_csv(\"experiment_results/final_tables/results_hmmer_model_sizes.csv\")\n",
    "table_hmmer_results_all_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ram_prompttuned_S = pd.read_csv(\"experiment_results/memory_usages/memory_usage_RITA_s_prompt.csv\")\n",
    "ram_prompttuned_M = pd.read_csv(\"experiment_results/memory_usages/memory_usage_RITA_m_prompt.csv\")\n",
    "ram_prompttuned_L = pd.read_csv(\"experiment_results/memory_usages/memory_usage_RITA_l_prompt.csv\")\n",
    "ram_prompttuned_XL = pd.read_csv(\"experiment_results/memory_usages/memory_usage_RITA_xl_prompt.csv\")\n",
    "\n",
    "ram_finetuned_S = pd.read_csv(\"experiment_results/memory_usages/memory_usage_RITA_s_finetuned.csv\")\n",
    "ram_finetuned_M = pd.read_csv(\"experiment_results/memory_usages/memory_usage_RITA_m_finetuned.csv\")\n",
    "ram_finetuned_L = pd.read_csv(\"experiment_results/memory_usages/memory_usage_RITA_l_finetuned.csv\")\n",
    "ram_finetuned_XL = pd.read_csv(\"experiment_results/memory_usages/memory_usage_RITA_xl_finetuned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>M</th>\n",
       "      <th>L</th>\n",
       "      <th>XL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prompt-tuned model (ours)</th>\n",
       "      <td>2890</td>\n",
       "      <td>7902</td>\n",
       "      <td>12723</td>\n",
       "      <td>18096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finetuned model</th>\n",
       "      <td>3793</td>\n",
       "      <td>10853</td>\n",
       "      <td>18881</td>\n",
       "      <td>28621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              S      M      L     XL\n",
       "Prompt-tuned model (ours)  2890   7902  12723  18096\n",
       "Finetuned model            3793  10853  18881  28621"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_ram_results_all_sizes = generate_ram_usages_table_comparison_prompttuned_finetuned([\"S\", \"M\", \"L\", \"XL\"],\n",
    "                                                                                          [ram_prompttuned_S, ram_prompttuned_M, ram_prompttuned_L, ram_prompttuned_XL],\n",
    "                                                                                          [ram_finetuned_S, ram_finetuned_M, ram_finetuned_L, ram_finetuned_XL])\n",
    "table_ram_results_all_sizes.to_csv(\"experiment_results/final_tables/results_ram_model_sizes.csv\")\n",
    "table_ram_results_all_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4e636d6250>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "activity_data = pd.read_csv(\"../activity_prediction_metrics/test.csv\").to_numpy()\n",
    "\n",
    "plt.figure(figsize=(6,4), dpi=200)\n",
    "\n",
    "keys, _, values = list(zip(*[t for t in activity_data if t[1] == 'pt']))\n",
    "plt.scatter(keys, values, c = '#0060fa', label='prompt-tuned')\n",
    "\n",
    "keys, _, values = list(zip(*[t for t in activity_data if t[1] == 'base']))\n",
    "plt.scatter(keys, values, c = '#5da03b', label='base')\n",
    "\n",
    "keys, _, values = list(zip(*[t for t in activity_data if t[1] == 'fine']))\n",
    "plt.scatter(keys, values, c = '#e8d138', label='finetuned')\n",
    "\n",
    "plt.rc('font', **{'size'   : '14'})\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
