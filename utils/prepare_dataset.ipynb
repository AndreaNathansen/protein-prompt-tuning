{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We used this notebook to create our datasets.\n",
    "This includes cleaning the raw dataset (substiture ambiguous AA and remove sequences with an X),\n",
    "clustering and splitting into train, validation and test set as well as generating txt files\n",
    "from the fasta datasets for finetuning with the Huggingface run_clm.py script\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from parse_clusters import parse_clusters\n",
    "from sequence_cleaning import remove_X, replace_amino_acids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean: remove sequences with X\n",
    "dataset = SeqIO.parse(\"../datasets/InterProUniprotPF03272.fasta\", \"fasta\")\n",
    "dataset_xremoved = remove_X(dataset)\n",
    "with open(\"../datasets/InterProUniprotPF03272_Xremoved.fasta\", 'w') as f:\n",
    "        SeqIO.write(dataset_xremoved, f, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the dataset\n",
    "devnull = open(os.devnull, 'w')\n",
    "subprocess.call(['bash', './clustering.sh'], stdout=devnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/validation/test\n",
    "clusters = parse_clusters(\"../datasets/clustered/InterProUniprotPF03272_all_seqs.fasta\")\n",
    "representatives = [c.members[0] for c in clusters]\n",
    "\n",
    "random_seed = 123456\n",
    "\n",
    "train_val_set, test_set = train_test_split(representatives, test_size=0.1, shuffle=True, random_state=random_seed)\n",
    "train_set, validation_set = train_test_split(train_val_set, test_size=1/9, shuffle=True, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ambigous AA\n",
    "prepared_train_set = replace_amino_acids(random_seed, train_set)\n",
    "prepared_validation_set = replace_amino_acids(random_seed, validation_set)\n",
    "prepared_test_set = replace_amino_acids(random_seed, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits to separate files\n",
    "with open(\"../datasets/InterProUniprotPF03272prepared_train.fasta\", \"w\") as handle:\n",
    "    SeqIO.write(prepared_train_set, handle, \"fasta\")\n",
    "\n",
    "with open(\"../datasets/InterProUniprotPF03272prepared_validation.fasta\", \"w\") as handle:\n",
    "    SeqIO.write(prepared_validation_set, handle, \"fasta\")\n",
    "\n",
    "with open(\"../datasets/InterProUniprotPF03272prepared_test.fasta\", \"w\") as handle:\n",
    "    SeqIO.write(prepared_test_set, handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "shutil.rmtree(\"../datasets/clustered\")\n",
    "shutil.rmtree(\"./tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate txt datasets, following the format that the RITA authors specify (https://github.com/lightonai/RITA/issues/10)\n",
    "records_train_seq = list(SeqIO.parse(\"../datasets/InterProUniprotPF03272prepared_train.fasta\", \"fasta\"))\n",
    "records_val_seq = list(SeqIO.parse(\"../datasets/InterProUniprotPF03272prepared_validation.fasta\", \"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_rita = \"<EOS>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = eos_token_rita.join([str(record.seq) for record in records_train_seq])\n",
    "with open(\"../datasets/InterProUniprotPF03272prepared_train.txt\", \"w\") as handle:\n",
    "    handle.write(text_train)\n",
    "\n",
    "text_val = eos_token_rita.join([str(record.seq) for record in records_val_seq])\n",
    "with open(\"../datasets/InterProUniprotPF03272prepared_validation.txt\", \"w\") as handle:\n",
    "    handle.write(text_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1135a5db4f333f85c89accac1201d40359c8614a7623692f674ab8f8e89645dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
