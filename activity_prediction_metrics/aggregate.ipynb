{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4302726149559021"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from esm_likelihood import get_esm_likelihood_scores\n",
    "#from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "#testset_file = '../datasets/InterProUniprotPF03272prepared_test.fasta'\n",
    "#testset = list(SeqIO.parse(testset_file, 'fasta'))\n",
    "\n",
    "# filter sequences with more than 1024 amino acids because ESM can't handle longer sequences\n",
    "#testset = [seq for seq in testset if len(seq) <= 1024]\n",
    "\n",
    "# Calculate cutoff (10th percentile of ESM likelihood scores for the test set)\n",
    "#testset_df = get_esm_likelihood_scores(testset)\n",
    "testset_df = pd.read_csv(\"intermediate/basemodel-RITA_l-generated.fasta_testset_scores.csv\")\n",
    "cutoff = testset_df['score'].quantile(q=0.1)\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "results = {}\n",
    "\n",
    "for file in glob.glob(\"intermediate/*fasta_scores.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    filtered = df[df['score'] > cutoff]\n",
    "    ids = list(filtered['id'])\n",
    "    results[file] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate/finetuned-RITA_s-generated.fasta_scores.csv 20\n",
      "intermediate/prompt-tuning-clustered-100-RITA_xl-fromvocab-True-seed-1-generated.fasta_scores.csv 18\n",
      "intermediate/prompt-tuning-clustered-100-RITA_s-fromvocab-True-seed-0-generated.fasta_scores.csv 4\n",
      "intermediate/prompt-tuning-clustered-100-RITA_l-fromvocab-True-seed-1-generated.fasta_scores.csv 8\n",
      "intermediate/prompt-tuning-clustered-100-RITA_m-fromvocab-True-seed-2-generated.fasta_scores.csv 7\n",
      "intermediate/prompt-tuning-clustered-100-RITA_l-fromvocab-True-seed-2-generated.fasta_scores.csv 10\n",
      "intermediate/prompt-tuning-clustered-100-RITA_xl-fromvocab-True-seed-0-generated.fasta_scores.csv 18\n",
      "intermediate/prompt-tuning-clustered-100-RITA_m-fromvocab-True-seed-1-generated.fasta_scores.csv 6\n",
      "intermediate/finetuned-RITA_xl-generated.fasta_scores.csv 81\n",
      "intermediate/prompt-tuning-clustered-100-RITA_xl-fromvocab-True-seed-2-generated.fasta_scores.csv 19\n",
      "intermediate/basemodel-RITA_m-generated.fasta_scores.csv 11\n",
      "intermediate/prompt-tuning-clustered-100-RITA_l-fromvocab-True-seed-0-generated.fasta_scores.csv 8\n",
      "intermediate/prompt-tuning-clustered-100-RITA_s-fromvocab-True-seed-2-generated.fasta_scores.csv 6\n",
      "intermediate/prompt-tuning-clustered-100-RITA_m-fromvocab-True-seed-0-generated.fasta_scores.csv 5\n",
      "intermediate/finetuned-RITA_l-generated.fasta_scores.csv 60\n",
      "intermediate/basemodel-RITA_xl-generated.fasta_scores.csv 10\n",
      "intermediate/basemodel-RITA_s-generated.fasta_scores.csv 5\n",
      "intermediate/basemodel-RITA_l-generated.fasta_scores.csv 15\n",
      "intermediate/prompt-tuning-clustered-100-RITA_s-fromvocab-True-seed-1-generated.fasta_scores.csv 5\n",
      "intermediate/finetuned-RITA_m-generated.fasta_scores.csv 33\n"
     ]
    }
   ],
   "source": [
    "for k,v in results.items():\n",
    "    print(k,len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RITA_s', 'fine', 10.362694300518134),\n",
       " ('RITA_s', 'pt', 2.0725388601036268),\n",
       " ('RITA_s', 'pt', 3.1088082901554404),\n",
       " ('RITA_s', 'base', 2.5906735751295336),\n",
       " ('RITA_s', 'pt', 2.5906735751295336),\n",
       " ('RITA_m', 'pt', 3.626943005181347),\n",
       " ('RITA_m', 'pt', 3.1088082901554404),\n",
       " ('RITA_m', 'base', 5.699481865284974),\n",
       " ('RITA_m', 'pt', 2.5906735751295336),\n",
       " ('RITA_m', 'fine', 17.098445595854923),\n",
       " ('RITA_l', 'pt', 4.1450777202072535),\n",
       " ('RITA_l', 'pt', 5.181347150259067),\n",
       " ('RITA_l', 'pt', 4.1450777202072535),\n",
       " ('RITA_l', 'fine', 31.088082901554404),\n",
       " ('RITA_l', 'base', 7.772020725388601),\n",
       " ('RITA_xl', 'pt', 9.32642487046632),\n",
       " ('RITA_xl', 'pt', 9.32642487046632),\n",
       " ('RITA_xl', 'fine', 41.968911917098445),\n",
       " ('RITA_xl', 'pt', 9.844559585492227),\n",
       " ('RITA_xl', 'base', 5.181347150259067)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "num_seqences_per_file = 193\n",
    "\n",
    "pattern = re.compile(\".*(RITA_\\w{1,2})-.*\")\n",
    "getModel = lambda filename: pattern.match(filename).groups()[0]\n",
    "\n",
    "data = [\n",
    "    (getModel(k), 'pt', len(v)*100/num_seqences_per_file) if 'prompt-tuning' in k \n",
    "    else ((getModel(k),'base',len(v)*100/num_seqences_per_file)) if 'basemodel' in k\n",
    "    else ((getModel(k),'fine',len(v)*100/num_seqences_per_file))\n",
    "    for k,v in results.items()\n",
    "]\n",
    "\n",
    "order = ['RITA_s', 'RITA_m', 'RITA_l', 'RITA_xl']\n",
    "data = sorted(data, key=lambda item: order.index(item[0]))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data, columns=['model', 'method', 'percentage']).to_csv('activity.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
